"""
Gemini AI Service - Xá»­ lÃ½ tÆ°Æ¡ng tÃ¡c vá»›i Google Gemini API
"""
import os
import google.generativeai as genai
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

class GeminiService:
    def __init__(self):
        """Khá»Ÿi táº¡o Gemini service vá»›i API key"""
        api_key = os.getenv("GEMINI_API_KEY")
        if not api_key:
            raise ValueError("GEMINI_API_KEY khÃ´ng Ä‘Æ°á»£c tÃ¬m tháº¥y trong file .env")
        
        # Cáº¥u hÃ¬nh Gemini
        genai.configure(api_key=api_key)
        
        # Khá»Ÿi táº¡o model (sá»­ dá»¥ng model má»›i)
        self.model = genai.GenerativeModel('gemini-1.5-flash')
        
        # System prompt cho chatbot cá»­a hÃ ng hoa (cÆ¡ báº£n)
        self.system_prompt = """
        Báº¡n lÃ  chatbot chuyÃªn nghiá»‡p cá»§a cá»­a hÃ ng hoa "Flower Garden".
        
        NHIá»†M Vá»¤:
        - Sá»­ dá»¥ng CHÃNH XÃC thÃ´ng tin tá»« database Ä‘Æ°á»£c cung cáº¥p
        - Tráº£ lá»i dá»±a trÃªn dá»¯ liá»‡u thá»±c táº¿, khÃ´ng bá»‹a Ä‘áº·t
        - Cung cáº¥p giÃ¡ cáº£, thÃ´ng tin sáº£n pháº©m cá»¥ thá»ƒ tá»« database
        - HÆ°á»›ng dáº«n khÃ¡ch hÃ ng Ä‘áº·t hÃ ng vÃ  liÃªn há»‡
        
        CÃCH TRáº¢ Lá»œI:
        - ThÃ¢n thiá»‡n, chuyÃªn nghiá»‡p vá»›i emoji hoa ğŸŒ¹ğŸŒ¸ğŸŒº
        - TrÃ­ch dáº«n CHÃNH XÃC giÃ¡ cáº£ vÃ  thÃ´ng tin tá»« database
        - Khi khÃ´ng cÃ³ thÃ´ng tin, thá»«a nháº­n vÃ  hÆ°á»›ng dáº«n liÃªn há»‡
        - LuÃ´n khuyáº¿n khÃ­ch Ä‘áº·t hÃ ng: 0123-456-789
        
        QUAN TRá»ŒNG: Chá»‰ sá»­ dá»¥ng thÃ´ng tin tá»« database Ä‘Æ°á»£c cung cáº¥p, khÃ´ng tá»± thÃªm thÃ´ng tin!
        """
    
    async def chat(self, user_message: str, context: str = "") -> str:
        """
        Gá»­i tin nháº¯n Ä‘áº¿n Gemini vÃ  nháº­n pháº£n há»“i
        
        Args:
            user_message: Tin nháº¯n tá»« user
            context: ThÃ´ng tin tá»« RAG system (tÃ¹y chá»n)
            
        Returns:
            str: Pháº£n há»“i tá»« AI
        """
        try:
            # Táº¡o prompt vá»›i context tá»« RAG (náº¿u cÃ³)
            if context:
                full_prompt = f"{self.system_prompt}\n\nTHÃ”NG TIN LIÃŠN QUAN:\n{context}\n\nKhÃ¡ch hÃ ng: {user_message}\nChatbot:"
            else:
                full_prompt = f"{self.system_prompt}\n\nKhÃ¡ch hÃ ng: {user_message}\nChatbot:"
            
            # Gá»­i request Ä‘áº¿n Gemini
            response = self.model.generate_content(full_prompt)
            
            # Tráº£ vá» response text
            return response.text
            
        except Exception as e:
            print(f"Lá»—i khi gá»i Gemini API: {e}")
            # Fallback response náº¿u AI lá»—i
            return "Xin lá»—i, tÃ´i Ä‘ang gáº·p sá»± cá»‘ ká»¹ thuáº­t. Vui lÃ²ng liÃªn há»‡ trá»±c tiáº¿p Ä‘á»ƒ Ä‘Æ°á»£c há»— trá»£ tá»‘t nháº¥t! ğŸŒ¸"

# Táº¡o instance global Ä‘á»ƒ sá»­ dá»¥ng
gemini_service = GeminiService()
